{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Color.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","outputId":"19154b2c-35b4-43ea-8f9b-9a5660e35c94","executionInfo":{"status":"ok","timestamp":1584935547112,"user_tz":240,"elapsed":641,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"id":"xMRN73Nu04fR","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lJOigEhpkH3i","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from IPython.core.debugger import set_trace\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import r2_score\n","from torch.utils.data import Dataset, DataLoader\n","from skimage import io,transform\n","from torchvision import transforms, utils\n","from sklearn.model_selection import train_test_split\n","import torchvision\n","import matplotlib.pyplot as plt\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mv70FwtmvKgH","colab_type":"text"},"source":["Remove unreadable images"]},{"cell_type":"code","metadata":{"id":"foJ2G4pwee-x","colab_type":"code","colab":{}},"source":["'''df = pd.read_csv('/content/drive/My Drive/Resonance/PrimaryData.csv')\n","l = []\n","root_dir = '/content/drive/My Drive/Resonance/Images'\n","print(len(df))\n","new_df = df.copy()\n","for i in range(len(list(df.iloc[:,0]))):\n","  spec_name = 'Num.'+str(df.iloc[i,0])+'.jpg'\n","  img_name = os.path.join(root_dir,spec_name)\n","  try: \n","    io.imread(img_name)\n","  except:\n","    new_df = new_df.drop(i)\n","print(len(new_df))\n","new_df.to_csv('/content/drive/My Drive/Resonance/PrimaryData.csv',index=False)'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z5UjgLvWvQmu","colab_type":"text"},"source":["Remove gray images"]},{"cell_type":"code","metadata":{"id":"W76LfqSrF_er","colab_type":"code","colab":{}},"source":["'''root_dir = '/content/drive/My Drive/Resonance/Images'\n","def is_grey_scale(img_path):\n","    img = Image.open(img_path).convert('RGB')\n","    w,h = img.size\n","    for i in range(w):\n","        for j in range(h):\n","            r,g,b = img.getpixel((i,j))\n","            if r != g != b: return False\n","    return True\n","gray = []\n","for i in range(len(image_names)):\n","  print(i)\n","  spec_name = 'Num.'+str(image_names.iloc[i])+'.jpg'\n","  if is_grey_scale(os.path.join(root_dir,spec_name)):\n","    gray.append(i)\n","df = pd.read_csv('/content/drive/My Drive/Resonance/PrimaryData.csv')\n","df = df.drop(gray)\n","df.to_csv('/content/drive/My Drive/Resonance/NoGrayPrimaryData.csv',index=False)'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEDtBLrDNBCU","colab_type":"code","colab":{}},"source":["import os\n","from PIL import Image\n","\n","df = pd.read_csv('/content/drive/My Drive/Resonance/NoGrayPrimaryData.csv')\n","\n","class ImageDataset(Dataset):\n","  def __init__(self,df,root_dir,transform=None):\n","    self.df = df\n","    self.root_dir = root_dir\n","    self.transform = transform\n","  def __len__(self):\n","    return len(self.df)\n","  \n","  def __getitem__(self,idx):\n","    spec_name = 'Num.'+str(self.df.iloc[idx,0])+'.jpg'\n","    img_name = os.path.join(self.root_dir,spec_name)\n","    image = Image.open(img_name).convert('RGB')\n","    ydata = self.df.iloc[idx,1]\n","    ydata = np.array(ydata)\n","    ydata = ydata.astype(float).reshape(-1,1)\n","\n","    if self.transform:\n","      image = self.transform(image)\n","    return image,ydata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"reg5LexGruHd","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/drive/My Drive/Resonance/NoGrayPrimaryData.csv')\n","\n","train,test = train_test_split(df,test_size=.2,random_state=2) \n","train = ImageDataset(train,'/content/drive/My Drive/Resonance/Images',transform=transforms.Compose([transforms.Resize((64,64)),transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[.5,.5,.5],\n","                             std=[.5,.5,.5])]))\n","\n","\n","test = ImageDataset(test,'/content/drive/My Drive/Resonance/Images',transform=transforms.Compose([transforms.Resize((64,64)),transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),transforms.Normalize(mean=[.5,.5,.5],\n","                             std=[.5,.5,.5])\n","        ]))\n","\n","train_loader = DataLoader(train, batch_size=96,\n","                        shuffle=False, num_workers=4,drop_last=True)\n","test_loader = DataLoader(test, batch_size=1,\n","                        shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJIusa5XiURu","colab_type":"code","colab":{}},"source":["for i_batch, (image,y) in enumerate(train_loader):\n","    print(i_batch, image.size(),\n","          y.size())\n","    test = y\n","    if i_batch ==5:\n","      test = image\n","      break\n","\n","    # observe 4th batch and stop."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vNSNTsUOM6s4","colab":{}},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n","    print(\"Running on the GPU\")\n","import torch.nn as nn\n","\n","\n","class ColorNet(nn.Module): \n","    def __init__(self):\n","        super(ColorNet, self).__init__()\n","        #feed forward layers\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3,32,kernel_size=5,stride=1,padding=2),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.MaxPool2d(kernel_size=2,stride=2)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(32,32,kernel_size=5,stride=1,padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2,stride=2)\n","        )\n","        \n","        self.dropout = nn.Dropout()\n","        self.linear1 = nn.Linear(32*8*8,100)\n","        self.linear2 = nn.Linear(100,100)\n","        self.linear3 = nn.Linear(100,14)\n","        \n","        \n","        #activations\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid() #Use sigmoid to convert the output into range (0,1)\n","        self.softmax = nn.Softmax()\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer2(out)\n","        out = out.reshape(out.size(0),-1)\n","        out = self.linear1(out)\n","        out = self.linear2(out)\n","        out = self.linear2(out)\n","        out = self.linear2(out)\n","        out = self.linear2(out)\n","        out = self.linear2(out)\n","        out = self.linear3(out)\n","        return out\n","#torch.manual_seed(0)\n","net=ColorNet()\n","\n","#opt=torch.optim.SGD(net.parameters(),lr=1e-2,nesterov=True,momentum=.2)\n","opt = torch.optim.Adam(net.parameters(),lr=1e-3)\n","\n","'''@torch.no_grad()\n","def init_weights(m):\n","    if type(m)==nn.Linear:\n","        m.weight.fill_(0)\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","        nn.init.xavier_uniform_(m.weight.data)\n","        #nn.init.xavier_uniform_(m.bias.data)\n","net.apply(init_weights)'''\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train, batch_size=96,\n","                        shuffle=True, num_workers=4,drop_last=True)\n","test_loader = DataLoader(test, batch_size=96,\n","                        shuffle=True, num_workers=4,drop_last=True)\n","\n","loss_list = []\n","acc_list = []\n","total_step = len(train_loader)\n","num_epochs = 25\n","i = 0\n","test_loader = DataLoader(test, batch_size=len(test),\n","                        shuffle=False, num_workers=4)\n","for epoch in range(num_epochs):\n","  print('epoch',epoch)\n","  i = 0\n","  if int(epoch+1) in [5,10,15,20,25,30]:   \n","    for i,(image,labels) in enumerate(test_loader):\n","      outputs = net(image)\n","      labels = labels.view(-1).long()\n","      _,predicted = torch.max(outputs.data,1)\n","      correct = (predicted==labels).sum().item()\n","      total = labels.size(0)\n","      acc = correct/total\n","      print('TEST ACCURACY:',acc)\n","  for i,(image,labels) in enumerate(train_loader):\n","    i+=1\n","    print('batch',i)\n","    outputs = net(image)\n","    labels = labels.view(-1).long()\n","    l = loss(outputs,labels)\n","    loss_list.append(l.item())\n","\n","    opt.zero_grad()\n","    l.backward()\n","    opt.step()\n","\n","    total = labels.size(0)\n","    _,predicted = torch.max(outputs.data,1)\n","    correct = (predicted==labels).sum().item()\n","    acc_list.append(correct/total)\n","\n","    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n","          .format(epoch + 1, num_epochs, i + 1, total_step, l.item(),\n","                  correct / total) * 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvl1Va_1rY6Z","colab_type":"code","outputId":"22e6b0bc-fb36-414f-d7e8-039d5050e573","executionInfo":{"status":"ok","timestamp":1584933600480,"user_tz":240,"elapsed":639,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["torch.save(net, '/content/drive/My Drive/Resonance/ColorNet.pt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ColorNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"buu28ALx45Hu","colab_type":"code","colab":{}},"source":["net = torch.load('/content/drive/My Drive/Resonance/ColorNet.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NSFPiN77oF4W","colab_type":"code","colab":{}},"source":["test_loader = DataLoader(test, batch_size=len(test),\n","                        shuffle=False, num_workers=4)\n","for i,(image,labels) in enumerate(test_loader):\n","  outputs = net(image)\n","  labels = labels.view(-1).long()\n","  _,predicted = torch.max(outputs.data,1)\n","  correct = (predicted==labels).sum().item()\n","  total = labels.size(0)\n","  acc = correct/total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2DJDgBON4Wr","colab_type":"code","outputId":"92e1a292-89e7-4d44-80eb-2a7aadae8e28","executionInfo":{"status":"ok","timestamp":1584934297947,"user_tz":240,"elapsed":25463,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["acc"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6303501945525292"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"72VYoM1ofzc8","colab_type":"code","colab":{}},"source":["def top3(num):\n","  outputs.data.numpy()[num]\n","  t = pd.DataFrame(nn.functional.softmax(outputs).detach().numpy()[num]).sort_values(0,ascending=False)  \n","  t['Color'] = cmatch['Unnamed: 0']\n","  top3 = list(t.iloc[:2].index)\n","  if labels[num].item() in top3:\n","    return 1\n","  else:\n","    return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-ALs-fmglf7","colab_type":"code","outputId":"53d51810-adc5-4bbd-e673-9f9bd46e436b","executionInfo":{"status":"ok","timestamp":1584935473180,"user_tz":240,"elapsed":1630,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["total = 0\n","for i in range(len(labels)):\n","  total+=top3(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bnSXbbZ-g04e","colab_type":"code","outputId":"d6148bef-6433-4da6-86e6-33349fe996bc","executionInfo":{"status":"ok","timestamp":1584935475857,"user_tz":240,"elapsed":800,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["total/len(labels)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7821011673151751"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"OjZEQy9fpmqN","colab_type":"code","colab":{}},"source":["def inspect(num):\n","  outputs.data.numpy()[num]\n","  npimg = image.numpy()[num]\n","  plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","  t = pd.DataFrame(nn.functional.softmax(outputs).detach().numpy()[num]).sort_values(0,ascending=False)\n","  \n","  t['Color'] = cmatch['Unnamed: 0']\n","  print(labels[num].item())\n","  print('label',list(codes.loc[codes['0']==labels[num].item()]['Unnamed: 0'])[0])\n","  print('pred',list(codes.loc[codes['0']==predicted[num].item()]['Unnamed: 0'])[0])\n","  return t"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHQfn9W-RNE6","colab_type":"code","colab":{}},"source":["codes = pd.read_csv('/content/drive/My Drive/Resonance/PrimaryColorCodes.csv')\n","\n","for i, (image,labels) in enumerate(test_loader):\n","  if i==3:\n","    npimg = image.numpy()[0]\n","    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","    outputs = net(image)\n","    labels = labels.view(-1).long()\n","    break\n","\n"],"execution_count":0,"outputs":[]}]}