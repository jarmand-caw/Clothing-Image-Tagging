{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Body.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","outputId":"7b6425d4-c959-41db-d4a3-a84d61d2cd67","executionInfo":{"status":"ok","timestamp":1584936240506,"user_tz":240,"elapsed":24911,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"id":"xMRN73Nu04fR","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lJOigEhpkH3i","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from IPython.core.debugger import set_trace\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import r2_score\n","from torch.utils.data import Dataset, DataLoader\n","from skimage import io,transform\n","from torchvision import transforms, utils\n","from sklearn.model_selection import train_test_split\n","import torchvision\n","import matplotlib.pyplot as plt\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bMdPAX9jvanl","colab_type":"text"},"source":["Block below is to check and make sure that all images are readable in the dataset. Only needs to be run once after a new category data set is made"]},{"cell_type":"code","metadata":{"id":"foJ2G4pwee-x","colab_type":"code","outputId":"d13bbe5b-104b-4328-959d-03e8e5fb337c","executionInfo":{"status":"ok","timestamp":1584824867323,"user_tz":240,"elapsed":511103,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import os\n","df = pd.read_csv('/content/drive/My Drive/Resonance/BodyData.csv')\n","l = []\n","root_dir = '/content/drive/My Drive/Resonance/Images'\n","print(len(df))\n","new_df = df.copy()\n","for i in range(len(list(df.iloc[:,0]))):\n","  spec_name = 'Num.'+str(df.iloc[i,0])+'.jpg'\n","  img_name = os.path.join(root_dir,spec_name)\n","  try: \n","    io.imread(img_name)\n","  except:\n","    new_df = new_df.drop(i)\n","print(len(new_df))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["818\n","809\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B8Hyl_XBvmI6","colab_type":"text"},"source":["Saving the new dataset without unreadable images over the original dataset. Usually only ~10 images are unreadable"]},{"cell_type":"code","metadata":{"id":"4xkf-qEgl4y5","colab_type":"code","colab":{}},"source":["new_df.to_csv('/content/drive/My Drive/Resonance/BodyData.csv',index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o8Lo850xv_xI","colab_type":"text"},"source":["Create the custom ImageDataset class. This will allow the dataset to be read by a pytorch dataloader, which allows for multiprocessing (faster loading) and batches (won't overload the ram)"]},{"cell_type":"code","metadata":{"id":"rEDtBLrDNBCU","colab_type":"code","colab":{}},"source":["import os\n","from PIL import Image\n","\n","class ImageDataset(Dataset):\n","  def __init__(self,df,root_dir,transform=None):\n","    self.df = df\n","    self.root_dir = root_dir\n","    self.transform = transform\n","  def __len__(self):\n","    return len(self.df)\n","  \n","  def __getitem__(self,idx):\n","    spec_name = 'Num.'+str(self.df.iloc[idx,0])+'.jpg'\n","    img_name = os.path.join(self.root_dir,spec_name)\n","    image = Image.open(img_name).convert('RGB')\n","    ydata = self.df.iloc[idx,1]\n","    ydata = np.array(ydata)\n","    ydata = ydata.astype(float).reshape(-1,1)\n","\n","    if self.transform:\n","      image = self.transform(image)\n","    return image,ydata"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Db5eDev2wUZh","colab_type":"text"},"source":["Please see comments in cell."]},{"cell_type":"code","metadata":{"id":"reg5LexGruHd","colab_type":"code","colab":{}},"source":["#Read in data for this category\n","df = pd.read_csv('/content/drive/My Drive/Resonance/BodyData.csv')\n","\n","#Split the data into training and testing sets so we can evaluate model performance\n","train,test = train_test_split(df,test_size=.2,random_state=2) \n","\n","#Load the train and test dataframes into train and test ImageDatasets\n","#Transformations here have several goals depending on the transformation:\n","#Reduce overfitting (random flip)\n","#Make it easier for the model to load and train (resize,normalize)\n","#Make it model readable (totensor)\n","train = ImageDataset(train,'/content/drive/My Drive/Resonance/Images',transform=transforms.Compose([transforms.Resize((64,64)),transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[.5,.5,.5],\n","                             std=[.5,.5,.5])]))\n","test = ImageDataset(test,'/content/drive/My Drive/Resonance/Images',transform=transforms.Compose([transforms.Resize((64,64)),transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),transforms.Normalize(mean=[.5,.5,.5],\n","                             std=[.5,.5,.5])\n","        ]))\n","\n","train_loader = DataLoader(train, batch_size=4,\n","                        shuffle=False, num_workers=4,drop_last=True)\n","test_loader = DataLoader(test, batch_size=1,\n","                        shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ug36HJDjxQFM","colab_type":"text"},"source":["Look at size of tensors in the loader. Used for debugging and entering appropriate dimensions into model"]},{"cell_type":"code","metadata":{"id":"CJIusa5XiURu","colab_type":"code","colab":{}},"source":["for i_batch, (image,y) in enumerate(train_loader):\n","    print(i_batch, image.size(),\n","          y.size())\n","    test1 = y\n","    if i_batch ==5:\n","      test1 = image\n","      break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RuEd_9ibuG9G","colab_type":"text"},"source":["Train net"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vNSNTsUOM6s4","colab":{}},"source":["#Running on GPU speeds up training time significantly on images\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n","    print(\"Running on the GPU\")\n","import torch.nn as nn\n","\n","\n","class BodyNet(nn.Module): \n","    def __init__(self):\n","        super(BodyNet, self).__init__()\n","        #feed forward layers\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3,32,kernel_size=5,stride=1,padding=2),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.MaxPool2d(kernel_size=2,stride=2)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(32,32,kernel_size=5,stride=1,padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2,stride=2)\n","        )\n","        self.dropout = nn.Dropout()\n","        self.linear1 = nn.Linear(32*8*8,1000)\n","        self.linear2 = nn.Linear(1000,5)\n","        \n","        \n","        #activations\n","        self.relu = nn.ReLU()\n","        self.sigmoid = nn.Sigmoid() #Use sigmoid to convert the output into range (0,1)\n","        self.softmax = nn.Softmax()\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer2(out)\n","        #out = self.layer2(out)\n","        #out = self.layer2(out)\n","        out = out.reshape(out.size(0),-1)\n","        out = self.linear1(out)\n","        out = self.linear2(out)\n","        return out\n","\n","#torch.manual_seed(0)\n","net=BodyNet()\n","\n","#opt=torch.optim.SGD(net.parameters(),lr=1e-2,nesterov=True,momentum=.2)\n","opt = torch.optim.Adam(net.parameters(),lr=1e-3)\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_loader = DataLoader(train, batch_size=96,\n","                        shuffle=True, num_workers=4,drop_last=True)\n","\n","loss_list = []\n","acc_list = []\n","total_step = len(train_loader)\n","num_epochs = 17\n","i = 0\n","test_loader = DataLoader(test, batch_size=len(test),\n","                        num_workers=4)\n","for epoch in range(num_epochs):\n","  print('epoch',epoch)\n","  if int((epoch+1)) in [5,10,15,20,25]:    \n","    for i,(image,labels) in enumerate(test_loader):\n","      outputs = net(image)\n","      labels = labels.view(-1).long()\n","      _,predicted = torch.max(outputs.data,1)\n","      correct = (predicted==labels).sum().item()\n","      total = labels.size(0)\n","      acc = correct/total\n","      print('TEST ACC: ',acc)\n","  i = 0\n","  for i,(image,labels) in enumerate(train_loader):\n","    i+=1\n","    print('batch',i)\n","    outputs = net(image)\n","    labels = labels.view(-1).long()\n","    l = loss(outputs,labels)\n","    loss_list.append(l.item())\n","\n","    opt.zero_grad()\n","    l.backward()\n","    opt.step()\n","\n","    total = labels.size(0)\n","    _,predicted = torch.max(outputs.data,1)\n","    correct = (predicted==labels).sum().item()\n","    acc_list.append(correct/total)\n","\n","    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n","          .format(epoch + 1, num_epochs, i + 1, total_step, l.item(),\n","                  correct / total) * 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvl1Va_1rY6Z","colab_type":"code","outputId":"08d3934d-699b-4c6e-da9b-c7b7f7d1cac9","executionInfo":{"status":"ok","timestamp":1584914811848,"user_tz":240,"elapsed":1172,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["torch.save(net, '/content/drive/My Drive/Resonance/BodyNet.pt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BodyNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NSFPiN77oF4W","colab_type":"code","colab":{}},"source":["test_loader = DataLoader(test, batch_size=len(test),\n","                        num_workers=4)\n","for i,(image,labels) in enumerate(test_loader):\n","  outputs = net(image)\n","  labels = labels.view(-1).long()\n","  _,predicted = torch.max(outputs.data,1)\n","  correct = (predicted==labels).sum().item()\n","  total = labels.size(0)\n","  acc = correct/total"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2DJDgBON4Wr","colab_type":"code","outputId":"ce1a1270-edda-4b84-d3d2-a51c9e5286a5","executionInfo":{"status":"ok","timestamp":1584914681569,"user_tz":240,"elapsed":66264,"user":{"displayName":"Jack Armand","photoUrl":"","userId":"14190996819119989804"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["acc"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9012345679012346"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"OjZEQy9fpmqN","colab_type":"code","colab":{}},"source":["def inspect(num):\n","  outputs.data.numpy()[num]\n","  npimg = image.numpy()[num]\n","  plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","  t = pd.DataFrame(outputs.data.numpy()[num]).sort_values(0)\n","  t['Color'] = cmatch['Unnamed: 0']\n","  print(labels[num].item())\n","  print('label',list(codes.loc[codes['0']==labels[num].item()]['Unnamed: 0'])[0])\n","  print('pred',list(codes.loc[codes['0']==predicted[num].item()]['Unnamed: 0'])[0])\n","  return t"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_sL3JC8yM5f","colab_type":"text"},"source":["Visualize train accuracy"]},{"cell_type":"code","metadata":{"id":"8lMEvLI5M6s7","colab_type":"code","colab":{}},"source":["plt.plot(acc_list,'r-o')\n","#plt.plot(test_r2s_store[100:],'b-o')\n","plt.xlabel('number of epochs')\n","plt.ylabel('r2')\n","#plt.ylim(0.85,1)\n","#plt.legend(('train','test'),loc='upper left')\n","plt.title('train acc wrt epochs')\n","plt.show()"],"execution_count":0,"outputs":[]}]}